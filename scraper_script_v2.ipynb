{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports parameters file, which contains login information\n",
    "import parameters as p\n",
    "#Web Scraping Tools\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as bs\n",
    "#DataFrame & Excel Exporting Tools\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog as fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scrape:\n",
    "    def __init__(self, c):\n",
    "        #utilize webdriver to log into LinkedIn\n",
    "        driver = webdriver.Chrome('/Users/shailesh/Documents/chromedriver')\n",
    "        self.driver = driver\n",
    "        \n",
    "        self.driver.get('https://www.linkedin.com/login?fromSignIn=true&trk=guest_homepage-basic_nav-header-signin')\n",
    "\n",
    "        #p.ln_user = LN username\n",
    "        username = self.driver.find_element_by_name('session_key')\n",
    "        username.send_keys(p.ln_user)\n",
    "\n",
    "        #p.ln_password = LN password\n",
    "        username = self.driver.find_element_by_name('session_password')\n",
    "        username.send_keys(p.ln_ps)\n",
    "\n",
    "        #clicks submit button for login\n",
    "        login = self.driver.find_element_by_class_name('login__form_action_container')\n",
    "        login.click()\n",
    "        \n",
    "        if(c == 0):\n",
    "            #initializes lists for dataframe \n",
    "            self.name = []\n",
    "            self.url = []\n",
    "            self.city = []\n",
    "            self.state = []\n",
    "            self.geoID = []\n",
    "            self.fYear = []\n",
    "            self.numEmployee = []\n",
    "            self.numLNE = []\n",
    "            self.overview = []\n",
    "            self.industry = []\n",
    "            self.specs = []\n",
    "            self.numRounds = []\n",
    "            self.totAmt = []\n",
    "            self.fundID = []\n",
    "\n",
    "        #call Retrieve function\n",
    "        self.retrieve()\n",
    "        \n",
    "    def retrieve(self):\n",
    "        #name = ['hive9', 'Lucd','Loadbalancer-org', 'ParkMyCloud', 'Rigado', 'FileCloud']\n",
    "        #name is input for company name\n",
    "        #can be replaced with an array and iterated through\n",
    "        \n",
    "        #single input\n",
    "        #url = input(\"Company URL(s) | If done, enter -1): \")\n",
    "        \n",
    "        #multiple input\n",
    "        links = list(map(str, input(\"Enter Company URL(s): \").split()))\n",
    "        links.append(-1)\n",
    "        #c = 0\n",
    "        \n",
    "        for url in links:\n",
    "            if(url == -1):\n",
    "                self.driver.quit()\n",
    "                choice = input('Select 1 to export current data to CSV | 2 to add onto an existing CSV | Anything else to exit\\n')\n",
    "                df = pd.DataFrame(list(zip(self.name, self.url, self.city, self.state, self.geoID, self.fYear, self.numEmployee, self.numLNE, self.overview, self.industry, self.specs, self.numRounds, self.totAmt, self.fundID)),\n",
    "                                 columns = ['Name', 'URL','City', 'State', 'Geo ID' ,'Founding Year', 'Number of Employees', 'Number of LinkedIn Employees', 'Overview', 'Industry', 'Specifications', 'Number of Funding Rounds', 'Total Funding Amount', 'Fund ID'])\n",
    "                print(df.head())\n",
    "                if(choice == '1'):\n",
    "                    #df.to_csv(r'/Users/shailesh/Programs/scrper/companies.csv', index=False, header=True)\n",
    "                    root = tk.Tk()\n",
    "                    c1 = tk.Canvas(root, width = 300, height = 300, bg = 'lightsteelblue2', relief = 'raised')\n",
    "                    c1.pack()\n",
    "                    \n",
    "                    def exportCSV():\n",
    "                        export_file_path = fd.asksaveasfilename(defaultextension='.csv')\n",
    "                        df.to_csv (export_file_path, index = False, header=True)\n",
    "                    \n",
    "                    saveAsButton_CSV = tk.Button(text='Export CSV', command=exportCSV, bg='green', fg='white', font=('helvetica', 12, 'bold'))\n",
    "                    c1.create_window(150, 150, window=saveAsButton_CSV)\n",
    "\n",
    "                    root.mainloop()\n",
    "                    \n",
    "                    exit()\n",
    "                elif(choice == '2'):\n",
    "                    df.to_csv(r'/Users/shailesh/Programs/scrper/companies.csv', mode='a',index=False, header=False)\n",
    "                else:\n",
    "                    exit()\n",
    "            else:\n",
    "                self.driver.get(url)\n",
    "                r = self.driver.page_source\n",
    "                #utilizes beautifulsoup to sift through source code\n",
    "                soup = bs(r, 'html5lib')\n",
    "\n",
    "                #Company Name\n",
    "                name = soup.find('h1', attrs={'class': 'org-top-card-summary__title t-24 t-black truncate'}) ['title']\n",
    "                #print('Name: ' + name)\n",
    "                self.name.append(name)\n",
    "                \n",
    "                #URL\n",
    "                self.url.append(url)\n",
    "                \n",
    "                #headquarters\n",
    "                hq = soup.find_all('div', attrs={'class': 'org-top-card-summary-info-list__info-item'})[1].getText()\n",
    "                hq = hq.strip()\n",
    "                hp = list(hq.split(\", \"))\n",
    "                #print('City: ' + hp[0])\n",
    "                self.city.append(hp[0])\n",
    "                #print('State: ' + hp[1])\n",
    "                self.state.append(hp[1])\n",
    "                \n",
    "                #automatic state disqualification parameter\n",
    "                #1 if Company HQ State falls within CA, NY, FL, MO, HI, or MA\n",
    "                if(hp[1] == 'CA' or hp[1] == 'NY' or hp[1] == 'MO' or hp[1] == 'HI' or hp[1] == 'FL' or hp[1] == 'MA' or hp[1] == 'California' or hp[1] == 'New York' or hp[1] == 'Missouri' or hp[1] == 'Hawaii' or hp[1] == 'Florida' or hp[1] == 'Massachusetts'):\n",
    "                    self.geoID.append(1)\n",
    "                else:\n",
    "                    self.geoID.append(0)\n",
    "        \n",
    "                #year founded\n",
    "                yearFounded = soup.find_all('dd', attrs={'class': 'org-page-details__definition-text t-14 t-black--light t-normal'})[-2].getText()\n",
    "                yearFounded = yearFounded.strip()\n",
    "                #print('Founding Year: ' + yearFounded)\n",
    "                self.fYear.append(yearFounded)\n",
    "                \n",
    "                #num of employees\n",
    "                numEmployees = soup.find('dd', attrs={'class': 'org-about-company-module__company-size-definition-text t-14 t-black--light mb1 fl'}).getText()\n",
    "                numEmployees = numEmployees.strip()\n",
    "                #print('Number of Employees: ' + numEmployees)\n",
    "                self.numEmployee.append(numEmployees)\n",
    "\n",
    "                #num of LN Employees\n",
    "                lnEmployees = soup.find('dd', attrs={'class': 'org-page-details__employees-on-linkedin-count t-14 t-black--light mb5'}).getText()\n",
    "                lnEmployees = lnEmployees.strip()\n",
    "                self.numLNE.append(lnEmployees)\n",
    "                \n",
    "                #overview\n",
    "                overview = soup.find('p', attrs={'class': 'break-words white-space-pre-wrap mb5 t-14 t-black--light t-normal'}).getText()\n",
    "                overview = overview.strip()\n",
    "                #print('Overview: \\n' + overview)\n",
    "                self.overview.append(overview)\n",
    "                \n",
    "                #industry\n",
    "                industry = soup.find_all('div', attrs={'class': 'org-top-card-summary-info-list__info-item'})[0].getText()\n",
    "                industry = industry.strip()\n",
    "                #print('\\nIndustry: ' + industry)\n",
    "                self.industry.append(industry)\n",
    "\n",
    "                #specialties\n",
    "                specs = soup.find_all('dd', attrs={'class': 'org-page-details__definition-text t-14 t-black--light t-normal'})[-1].getText()\n",
    "                specs = specs.strip()\n",
    "                #print('Specifications: ' + specs)\n",
    "                self.specs.append(specs)\n",
    "\n",
    "                #capital raised $ & round type\n",
    "                try:\n",
    "                    cb_link = soup.find('a', attrs={'data-control-name': 'funding_all_rounds_link'}) ['href']\n",
    "                    self.driver.get(cb_link)\n",
    "                    r = self.driver.page_source\n",
    "                    soup = bs(r, 'html5lib')\n",
    "                    #print('cb_link')\n",
    "                    try:\n",
    "                        #Number of Funding Rounds\n",
    "                        numFundRounds = soup.find_all('span', attrs={'class': 'bigValueItemLabelOrData flex-none layout-column layout-align-center-start'})[0].getText()\n",
    "                        numFundRounds = numFundRounds.strip()\n",
    "                        #print('Number of Funding Rounds: ' + numFundRounds)\n",
    "                        self.numRounds.append(numFundRounds)\n",
    "                        \n",
    "                        #Total Funding Amount\n",
    "                        totFundAmt = soup.find_all('span', attrs={'class': 'bigValueItemLabelOrData flex-none layout-column layout-align-center-start'})[1].getText()\n",
    "                        totFundAmt = totFundAmt.strip()\n",
    "                        #print('Total Funding Amount: ' + totFundAmt)\n",
    "                        self.totAmt.append(totFundAmt)\n",
    "                        \n",
    "                        #Funding ID Parameter: Indicates whether data was pulled from Crunchbase, LN, or NA\n",
    "                        #1 indicates Crunchbase\n",
    "                        self.fundID.append(1)\n",
    "                        #c = c + 1\n",
    "                    except:\n",
    "                        try:\n",
    "                            self.driver.get(url)\n",
    "                            r = self.driver.page_source\n",
    "                            soup = bs(r, 'html5lib')\n",
    "                            #Number of Funding Rounds\n",
    "                            numFundRounds = soup.find('div', attrs={'class': 'org-funding__links t-14 t-black--light t-normal'}).getText()\n",
    "                            numFundRounds = numFundRounds.strip()\n",
    "                            #print('Number of Funding Rounds: ' + numFundRounds)\n",
    "                            self.numRounds.append(numFundRounds)\n",
    "\n",
    "                            #Total Funding Amount\n",
    "                            totFundAmt = soup.find('span', attrs={'class': 't-24 t-light t-black--light'}).getText()\n",
    "                            totFundAmt = totFundAmt.strip()\n",
    "                            #print('Total Funding Amount: ' + totFundAmt)\n",
    "                            self.totAmt.append(totFundAmt)\n",
    "                            \n",
    "                            #Funding ID Parameter: Indicates whether data was pulled from Crunchbase, LN, or NA\n",
    "                            #2 indicates LinkedIn\n",
    "                            self.fundID.append(2)\n",
    "                            #c = c + 1\n",
    "                        except:\n",
    "                            self.numRounds.append('Not Available')\n",
    "                            self.totAmt.append('Not Available')\n",
    "                            \n",
    "                            #Funding ID Parameter: Indicates whether data was pulled from Crunchbase, LN, or NA\n",
    "                            #0 indicates Not Available\n",
    "                            self.fundID.append(0)\n",
    "                            #c = c + 1\n",
    "                except:\n",
    "                    try:\n",
    "                        self.driver.get(url)\n",
    "                        r = self.driver.page_source\n",
    "                        soup = bs(r, 'html5lib')\n",
    "                        #Number of Funding Rounds\n",
    "                        numFundRounds = soup.find('div', attrs={'class': 'org-funding__links t-14 t-black--light t-normal'}).getText()\n",
    "                        numFundRounds = numFundRounds.strip()\n",
    "                        #print('Number of Funding Rounds: ' + numFundRounds)\n",
    "                        self.numRounds.append(numFundRounds)\n",
    "                        \n",
    "                        #Total Funding Amount\n",
    "                        totFundAmt = soup.find('span', attrs={'class': 't-24 t-light t-black--light'}).getText()\n",
    "                        totFundAmt = totFundAmt.strip()\n",
    "                        #print('Total Funding Amount: ' + totFundAmt)\n",
    "                        self.totAmt.append(totFundAmt)\n",
    "                        \n",
    "                        #Funding ID Parameter: Indicates whether data was pulled from Crunchbase, LN, or NA\n",
    "                        #2 indicates LinkedIn\n",
    "                        self.fundID.append(2)\n",
    "                        #c = c + 1\n",
    "                    except:\n",
    "                        self.numRounds.append('Not Available')\n",
    "                        self.totAmt.append('Not Available')\n",
    "                        \n",
    "                        #Funding ID Parameter: Indicates whether data was pulled from Crunchbase, LN, or NA\n",
    "                        #0 indicates Not Available\n",
    "                        self.fundID.append(0)\n",
    "                        #c = c + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Company URL(s): https://www.linkedin.com/company/hive9/about/ https://www.linkedin.com/company/parkmycloud/about/ \n",
      "Select 1 to export current data to CSV | 2 to add onto an existing CSV | Anything else to exit\n",
      "1\n",
      "          Name                                                URL      City  \\\n",
      "0        Hive9      https://www.linkedin.com/company/hive9/about/    Austin   \n",
      "1  ParkMyCloud  https://www.linkedin.com/company/parkmycloud/a...  Sterling   \n",
      "\n",
      "      State  Geo ID Founding Year Number of Employees  \\\n",
      "0     Texas       0          2015     11-50 employees   \n",
      "1  Virginia       0          2015      2-10 employees   \n",
      "\n",
      "                        Number of LinkedIn Employees  \\\n",
      "0  17 on LinkedIn\\n            \\n  \\n\\n\\n\\n    In...   \n",
      "1  13 on LinkedIn\\n            \\n  \\n\\n\\n\\n    In...   \n",
      "\n",
      "                                            Overview           Industry  \\\n",
      "0  Hive9 is the marketing performance management ...  Computer Software   \n",
      "1  ParkMyCloud, a Turbonomic company, provides an...  Computer Software   \n",
      "\n",
      "                                      Specifications  \\\n",
      "0  Marketing Technology, Marketing Performance an...   \n",
      "1  cloud computing, amazon web services, cloud, M...   \n",
      "\n",
      "       Number of Funding Rounds Total Funding Amount  Fund ID  \n",
      "0                         $7.8M               20,533        1  \n",
      "1  ParkMyCloud · 4 total rounds               US$ 1M        2  \n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    Scrape(0)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
